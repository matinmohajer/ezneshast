import { NextRequest, NextResponse } from "next/server";
import { ElevenLabsClient } from "@elevenlabs/elevenlabs-js";
import Groq from "groq-sdk";
import { MEETING_PROCESSOR_CONFIG } from "@/lib/config";
import {
  checkTokenLimits,
  truncateForTokenLimit,
  getRecommendedModel,
} from "@/lib/token-management";
import {
  chunkTranscript,
  mergeChunkSummaries,
  getChunkingRecommendations,
  TranscriptChunk,
} from "@/lib/transcript-chunker";

/**
 * Create a fallback summary when LLM summarization fails
 */
function createFallbackSummary(
  transcript: string,
  language: "fa" | "en" = "fa"
): string {
  if (language === "fa") {
    return `### üìå ÿÆŸÑÿßÿµŸá ÿÆŸàÿØ⁄©ÿßÿ± ÿ¨ŸÑÿ≥Ÿá

**ÿ™Ÿàÿ¨Ÿá**: ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ŸáŸàÿ¥ŸÖŸÜÿØ ÿ®ÿß ŸÖÿ¥⁄©ŸÑ ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ. ÿß€åŸÜ ÿÆŸÑÿßÿµŸá ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿßÿ≥ÿ™.

#### üìä ÿßÿ∑ŸÑÿßÿπÿßÿ™ ⁄©ŸÑ€å
- **ÿ∑ŸàŸÑ ŸÖÿ™ŸÜ**: ${transcript.length} ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±
- **ÿ™ÿÆŸÖ€åŸÜ ÿ≤ŸÖÿßŸÜ**: ${Math.round(transcript.length / 200)} ÿØŸÇ€åŸÇŸá ÿµÿ≠ÿ®ÿ™

#### üìù ŸÜ⁄©ÿßÿ™ ⁄©ŸÑ€åÿØ€å
- ŸÖÿ™ŸÜ ÿ¨ŸÑÿ≥Ÿá ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿ¥ÿØŸá ÿßÿ≥ÿ™
- ÿ®ÿ±ÿß€å ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ÿØŸÇ€åŸÇ‚Äåÿ™ÿ±ÿå ŸÑÿ∑ŸÅÿßŸã ÿØŸàÿ®ÿßÿ±Ÿá ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ
- €åÿß ŸÅÿß€åŸÑ ÿµŸàÿ™€å ⁄©Ÿàÿ™ÿßŸá‚Äåÿ™ÿ±€å ÿ¢ŸæŸÑŸàÿØ ⁄©ŸÜ€åÿØ

---
*ÿß€åŸÜ ÿÆŸÑÿßÿµŸá ÿ®Ÿá ÿØŸÑ€åŸÑ ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØÿå ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿßÿ≥ÿ™.*`;
  } else {
    return `### üìå Auto-Generated Meeting Summary

**Note**: Smart summarization encountered an issue. This summary was auto-generated.

#### üìä General Information
- **Text Length**: ${transcript.length} characters
- **Estimated Duration**: ${Math.round(
      transcript.length / 200
    )} minutes of speech

#### üìù Key Points
- Meeting transcript was successfully processed
- For accurate summarization, please try again
- Or upload a shorter audio file

---
*This summary was auto-generated due to an error in smart processing.*`;
  }
}

export async function POST(request: NextRequest) {
  try {
    // Check for required API keys
    if (!process.env.ELEVENLABS_API_KEY) {
      return NextResponse.json(
        { error: "ELEVENLABS_API_KEY missing" },
        { status: 500 }
      );
    }

    if (!process.env.GROQ_API_KEY) {
      return NextResponse.json(
        { error: "GROQ_API_KEY missing" },
        { status: 500 }
      );
    }

    console.log("[voice-meeting-minutes] Received POST request");

    const formData = await request.formData();
    const audioFile = formData.get("audio") as Blob | null;

    if (!audioFile) {
      console.log("[voice-meeting-minutes] No audio file in formData");
      return NextResponse.json(
        { error: "`audio` field required" },
        { status: 400 }
      );
    }

    console.log("[voice-meeting-minutes] Audio file received:", {
      size: audioFile.size,
      type: audioFile.type,
    });

    // Step 1: Transcribe with ElevenLabs Scribe v1
    console.log(
      "[voice-meeting-minutes] Starting transcription with ElevenLabs..."
    );

    const elevenlabs = new ElevenLabsClient({
      apiKey: process.env.ELEVENLABS_API_KEY,
    });

    const transcription = await elevenlabs.speechToText.convert({
      file: audioFile,
      modelId: "scribe_v1",
      tagAudioEvents: true,
      languageCode: "fa", // Persian
      diarize: true,
    });

    console.log("[voice-meeting-minutes] ElevenLabs transcription completed");

    // Handle different response types from ElevenLabs
    let transcriptText: string;

    if (typeof transcription === "string") {
      transcriptText = transcription;
    } else if (transcription && typeof transcription === "object") {
      // Check for text property in various possible locations
      if ("text" in transcription && typeof transcription.text === "string") {
        transcriptText = transcription.text;
      } else if (
        "transcription" in transcription &&
        typeof transcription.transcription === "string"
      ) {
        transcriptText = transcription.transcription;
      } else if (
        "segments" in transcription &&
        Array.isArray(transcription.segments)
      ) {
        // If it's a multichannel response, extract text from segments
        transcriptText = transcription.segments
          .map((segment: { text?: string }) => segment.text || "")
          .join(" ");
      } else {
        transcriptText = JSON.stringify(transcription);
      }
    } else {
      transcriptText = "No transcription result";
    }

    console.log("[voice-meeting-minutes] Transcript extracted:", {
      length: transcriptText.length,
      preview: transcriptText.slice(0, 100),
    });

    // Step 2: Summarize with Groq
    console.log("[voice-meeting-minutes] Starting summarization with Groq...");

    const groq = new Groq({
      apiKey: process.env.GROQ_API_KEY,
    });

    // Use the model from config instead of hardcoding
    let model: string = MEETING_PROCESSOR_CONFIG.summarization.model;

    const systemPrompt = `ÿ¥ŸÖÿß €å⁄© ÿØÿ≥ÿ™€åÿßÿ± Ÿáÿ≥ÿ™€åÿØ ⁄©Ÿá ÿ®ÿß€åÿØ ÿßÿ≤ ŸÖÿ™ŸÜ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿ¥ÿØŸá €å⁄© ÿ¨ŸÑÿ≥Ÿá ⁄©ÿßÿ±€å (ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å) ÿµŸàÿ±ÿ™ÿ¨ŸÑÿ≥Ÿá ÿ±ÿ≥ŸÖ€å Ÿà ÿ®€å‚Äåÿ∑ÿ±ŸÅ ÿ™Ÿá€åŸá ⁄©ŸÜ€åÿØ.

ŸÖÿ™ŸÜ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ¥ÿßŸÖŸÑ ÿ¥ŸàÿÆ€åÿå ÿ≥⁄©Ÿàÿ™ÿå ÿµÿ≠ÿ®ÿ™‚ÄåŸáÿß€å ÿ®€å‚Äåÿ±ÿ®ÿ∑ €åÿß ÿ™⁄©ÿ±ÿßÿ±€å ÿ®ÿßÿ¥ÿØ. 
ŸÑÿ∑ŸÅÿßŸã ŸÅŸÇÿ∑ ÿ®ÿÆÿ¥‚ÄåŸáÿß€å ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß ŸÖÿ®ÿßÿ≠ÿ´ ⁄©ÿßÿ±€å Ÿà ÿßÿ≥⁄©ÿ±ÿßŸÖ ÿ±ÿß ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ⁄©ŸÜ€åÿØ.

Ÿàÿ∏ÿß€åŸÅ ÿ¥ŸÖÿß:
1. ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ŸÖÿ®ÿßÿ≠ÿ´ ŸÖŸáŸÖ ÿ¨ŸÑÿ≥Ÿá ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿ±ÿ≥ŸÖ€å.
2. ÿ≠ÿ∞ŸÅ ⁄©ÿßŸÖŸÑ Ÿáÿ±⁄ØŸàŸÜŸá ŸÜÿ∏ÿ± ÿ¥ÿÆÿµ€åÿå ÿ¥ŸàÿÆ€åÿå €åÿß ŸÖÿ≠ÿ™Ÿàÿß€å ŸÜÿßŸÖÿ±ÿ™ÿ®ÿ∑.
3. ÿØÿ≥ÿ™Ÿá‚Äåÿ®ŸÜÿØ€å ÿÆÿ±Ÿàÿ¨€å ÿØÿ± ŸÇÿßŸÑÿ® ÿ≤€åÿ±:

### üìå ÿµŸàÿ±ÿ™ÿ¨ŸÑÿ≥Ÿá
- **ÿ™ÿßÿ±€åÿÆ ÿ¨ŸÑÿ≥Ÿá:** [ÿß⁄Øÿ± ÿ∞⁄©ÿ± ÿ¥ÿØ ÿ®ŸÜŸà€åÿ≥€åÿØÿå ÿØÿ± ÿ∫€åÿ± ÿß€åŸÜÿµŸàÿ±ÿ™ ÿÆÿßŸÑ€å ÿ®⁄Øÿ∞ÿßÿ±€åÿØ]  
- **ŸÜŸàÿπ ÿ¨ŸÑÿ≥Ÿá:** ÿ®ÿ±ŸÜÿßŸÖŸá‚Äåÿ±€åÿ≤€å / ⁄Øÿ±ŸàŸÖ€åŸÜ⁄Ø / ÿßÿ≥ÿ™ŸÜÿØÿ¢Ÿæ / ÿ≥ÿß€åÿ± (ÿØÿ± ÿµŸàÿ±ÿ™ ÿ™ÿ¥ÿÆ€åÿµ)  

#### ‚úÖ ÿ™ÿµŸÖ€åŸÖÿßÿ™ ⁄Øÿ±ŸÅÿ™Ÿá‚Äåÿ¥ÿØŸá
[ÿ™ŸÖÿßŸÖ ÿ™ÿµŸÖ€åŸÖ‚ÄåŸáÿß€å ŸÇÿ∑ÿπ€å ⁄©Ÿá ÿ™€åŸÖ ÿ®Ÿá ÿ¢ŸÜ ÿ±ÿ≥€åÿØ]

#### üìù Ÿàÿ∏ÿß€åŸÅ Ÿà ÿßŸÇÿØÿßŸÖ‚ÄåŸáÿß
[⁄©ÿßÿ±Ÿáÿß€å ŸÖÿ¥ÿÆÿµÿå ÿ¥ÿßŸÖŸÑ:  
- ÿ¥ÿ±ÿ≠ ⁄©ÿßÿ±  
- ŸÖÿ≥ÿ¶ŸàŸÑ (ÿØÿ± ÿµŸàÿ±ÿ™ ÿ∞⁄©ÿ± ŸÜÿßŸÖ)  
- ÿ≤ŸÖÿßŸÜ‚Äåÿ®ŸÜÿØ€å €åÿß ÿ∂ÿ±ÿ®‚ÄåÿßŸÑÿπÿ¨ŸÑ (ÿß⁄Øÿ± ⁄ØŸÅÿ™Ÿá ÿ¥ÿØ)  
]

#### ‚ùì ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿ®ÿßÿ≤ / ŸÜ€åÿßÿ≤ŸÖŸÜÿØ Ÿæ€å⁄Ø€åÿ±€å
[ŸÖŸàÿ∂Ÿàÿπÿßÿ™€å ⁄©Ÿá ŸÜÿ™€åÿ¨Ÿá‚Äå⁄Ø€åÿ±€å ŸÜÿ¥ÿØ Ÿà ÿ®ÿß€åÿØ ÿØÿ± ÿ¨ŸÑÿ≥ÿßÿ™ ÿ®ÿπÿØ€å ÿ®ÿ±ÿ±ÿ≥€å ÿ¥ŸàÿØ]

---

ÿ±ÿßŸáŸÜŸÖÿß:
- ÿßÿ≤ ÿ™⁄©ÿ±ÿßÿ± ŸÖÿ®ÿßÿ≠ÿ´ ŸÖÿ¥ÿßÿ®Ÿá ÿÆŸàÿØÿØÿßÿ±€å ⁄©ŸÜ€åÿØÿå ŸÅŸÇÿ∑ ŸÜÿ™€åÿ¨Ÿá ŸÜŸáÿß€å€å ÿ±ÿß ÿ∞⁄©ÿ± ⁄©ŸÜ€åÿØ.
- ÿß⁄Øÿ± ŸÖÿ≥ÿ¶ŸàŸÑ €åÿß ÿ≤ŸÖÿßŸÜ‚Äåÿ®ŸÜÿØ€å ÿ∞⁄©ÿ± ŸÜÿ¥ÿØÿå ÿÆÿßŸÑ€å ÿ®⁄Øÿ∞ÿßÿ±€åÿØ.
- ÿÆÿ±Ÿàÿ¨€å ÿ®ÿß€åÿØ ⁄©Ÿàÿ™ÿßŸáÿå ÿ¥ŸÅÿßŸÅ Ÿà ÿ≥ÿßÿÆÿ™ÿßÿ±€åÿßŸÅÿ™Ÿá ÿ®ÿßÿ¥ÿØ.
- Ÿá€å⁄Ü ŸÜÿ∏ÿ± €åÿß ÿ™ÿ≠ŸÑ€åŸÑ ÿ¥ÿÆÿµ€å ÿßÿ∂ÿßŸÅŸá ŸÜ⁄©ŸÜ€åÿØ.`;

    const userPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ:

${transcriptText}`;

    // Check if we need to chunk the transcript
    const chunkingRecommendations = getChunkingRecommendations(
      transcriptText.length,
      "fa"
    );
    console.log(`[voice-meeting-minutes] Chunking recommendations:`, {
      transcriptLength: transcriptText.length,
      estimatedTokens: chunkingRecommendations.estimatedTokens,
      estimatedChunks: chunkingRecommendations.estimatedChunks,
      maxTokensPerChunk:
        chunkingRecommendations.recommendedStrategy.maxTokensPerChunk,
      willChunk: chunkingRecommendations.estimatedChunks > 1,
    });

    let meetingMinutes: string;
    let summarizationSuccess = false;
    let summarizationError: string | null = null;
    let chunks: TranscriptChunk[] = [];

    try {
      if (chunkingRecommendations.estimatedChunks > 1) {
        // Need to chunk the transcript
        console.log(
          `[voice-meeting-minutes] Chunking transcript into ${chunkingRecommendations.estimatedChunks} parts`
        );

        try {
          chunks = chunkTranscript(
            transcriptText,
            chunkingRecommendations.recommendedStrategy,
            "fa"
          );
          console.log(
            `[voice-meeting-minutes] Created ${chunks.length} chunks:`,
            chunks.map((chunk) => ({
              id: chunk.id,
              tokens: chunk.estimatedTokens,
              length: chunk.content.length,
            }))
          );

          if (chunks.length === 0) {
            console.log(
              "[voice-meeting-minutes] WARNING: No chunks created, falling back to single chunk processing"
            );
            throw new Error("Chunking failed - no chunks created");
          }
        } catch (chunkingError) {
          console.error(
            "[voice-meeting-minutes] Chunking failed, falling back to single chunk processing:",
            chunkingError
          );
          throw chunkingError; // This will be caught by the outer try-catch
        }

        // Process each chunk with the appropriate model
        const chunkSummaries: string[] = [];

        for (let i = 0; i < chunks.length; i++) {
          const chunk = chunks[i];
          console.log(
            `[voice-meeting-minutes] Processing chunk ${i + 1}/${
              chunks.length
            } (${chunk.estimatedTokens} tokens)`
          );

          // Select appropriate model for this chunk
          let chunkModel = model;
          if (chunk.estimatedTokens > 12000) {
            chunkModel = "mixtral-8x7b-32768";
          } else if (chunk.estimatedTokens > 8000) {
            chunkModel = "llama-3.3-70b-versatile";
          }

          const chunkUserPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ:

${chunk.content}`;

          try {
            const chunkCompletion = await groq.chat.completions.create({
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: chunkUserPrompt,
                },
              ],
              model: chunkModel,
              temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
              max_tokens: 2000,
            });

            const chunkSummary =
              chunkCompletion.choices[0]?.message?.content ||
              "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
            chunkSummaries.push(chunkSummary);

            console.log(
              `[voice-meeting-minutes] Chunk ${
                i + 1
              } processed successfully with model ${chunkModel}`
            );

            // Add small delay between chunks to avoid rate limiting
            if (i < chunks.length - 1) {
              await new Promise((resolve) => setTimeout(resolve, 1000));
            }
          } catch (error) {
            console.error(
              `[voice-meeting-minutes] Error processing chunk ${i + 1}:`,
              error
            );

            // Try with a different model as fallback
            try {
              console.log(
                `[voice-meeting-minutes] Retrying chunk ${
                  i + 1
                } with fallback model`
              );
              const fallbackModel = "llama-3.1-8b-instant"; // Highest capacity model

              const fallbackCompletion = await groq.chat.completions.create({
                messages: [
                  {
                    role: "system",
                    content: systemPrompt,
                  },
                  {
                    role: "user",
                    content: chunkUserPrompt,
                  },
                ],
                model: fallbackModel,
                temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
                max_tokens: 2000,
              });

              const fallbackSummary =
                fallbackCompletion.choices[0]?.message?.content ||
                "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
              chunkSummaries.push(fallbackSummary);
              console.log(
                `[voice-meeting-minutes] Chunk ${
                  i + 1
                } processed with fallback model ${fallbackModel}`
              );
            } catch (fallbackError) {
              console.error(
                `[voice-meeting-minutes] Fallback also failed for chunk ${
                  i + 1
                }:`,
                fallbackError
              );
              chunkSummaries.push(
                `ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿÆÿ¥ ${i + 1}: ${
                  error instanceof Error ? error.message : "Unknown error"
                }`
              );
            }
          }
        }

        // Merge all chunk summaries
        console.log("[voice-meeting-minutes] Merging chunk summaries...");
        meetingMinutes = mergeChunkSummaries(chunkSummaries, "fa");
        console.log(
          `[voice-meeting-minutes] Final merged summary length: ${meetingMinutes.length} characters`
        );
      } else {
        // No chunking needed, process normally
        console.log(
          "[voice-meeting-minutes] No chunking needed, processing normally"
        );

        // Check token limits and get recommended action
        const tokenCheck = checkTokenLimits(
          systemPrompt,
          userPrompt,
          model,
          "fa"
        );
        console.log(`[voice-meeting-minutes] Token check:`, {
          estimatedTokens: tokenCheck.estimatedTokens,
          recommendedAction: tokenCheck.recommendedAction,
          isWithinLimit: tokenCheck.isWithinLimit,
        });

        // Handle token limit issues
        if (tokenCheck.recommendedAction === "error") {
          // Instead of throwing error, try with a different model
          console.log(
            "[voice-meeting-minutes] Token limit exceeded, trying with recommended model"
          );
          const recommendedModel = getRecommendedModel(
            tokenCheck.estimatedTokens
          );
          console.log(
            `[voice-meeting-minutes] Switching to recommended model: ${recommendedModel}`
          );
          model = recommendedModel;
        }

        if (tokenCheck.recommendedAction === "truncate") {
          console.log(
            "[voice-meeting-minutes] Truncating transcript to fit token limits"
          );
          const maxTokensForTranscript = 6000; // Leave room for system prompt
          transcriptText = truncateForTokenLimit(
            transcriptText,
            maxTokensForTranscript,
            "fa"
          );
          console.log(
            `[voice-meeting-minutes] Transcript truncated to ${transcriptText.length} characters`
          );

          // Recreate user prompt with truncated transcript
          const truncatedUserPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ:

${transcriptText}`;

          // Recheck token limits
          const newTokenCheck = checkTokenLimits(
            systemPrompt,
            truncatedUserPrompt,
            model,
            "fa"
          );
          if (!newTokenCheck.isWithinLimit) {
            // Try with a different model
            const recommendedModel = getRecommendedModel(
              newTokenCheck.estimatedTokens
            );
            console.log(
              `[voice-meeting-minutes] Switching to recommended model: ${recommendedModel}`
            );
            model = recommendedModel;
          }
        }

        // Process the transcript
        try {
          const completion = await groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: systemPrompt,
              },
              {
                role: "user",
                content: userPrompt,
              },
            ],
            model: model, // Use config model instead of hardcoded one
            temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
            max_tokens: 2000,
          });

          meetingMinutes =
            completion.choices[0]?.message?.content || "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
          summarizationSuccess = true;
        } catch (apiError) {
          console.error(
            "[voice-meeting-minutes] API call failed, trying with fallback model:",
            apiError
          );

          // Try with the highest capacity model as last resort
          try {
            const lastResortModel = "llama-3.1-8b-instant";
            console.log(
              `[voice-meeting-minutes] Trying with last resort model: ${lastResortModel}`
            );

            const fallbackCompletion = await groq.chat.completions.create({
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: userPrompt,
                },
              ],
              model: lastResortModel,
              temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
              max_tokens: 2000,
            });

            meetingMinutes =
              fallbackCompletion.choices[0]?.message?.content ||
              "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
            summarizationSuccess = true;
            model = lastResortModel; // Update the model used
            console.log(
              "[voice-meeting-minutes] Successfully processed with fallback model"
            );
          } catch (finalError) {
            console.error(
              "[voice-meeting-minutes] All models failed:",
              finalError
            );
            throw finalError; // This will be caught by the outer try-catch
          }
        }
      }
    } catch (error) {
      console.error("[voice-meeting-minutes] Summarization failed:", error);
      summarizationError =
        error instanceof Error ? error.message : "Unknown error";

      // Create a fallback summary based on the transcript
      meetingMinutes = createFallbackSummary(transcriptText, "fa");
      console.log(
        "[voice-meeting-minutes] Using fallback summary due to summarization failure"
      );
    }

    console.log("[voice-meeting-minutes] Summarization completed:", {
      success: summarizationSuccess,
      error: summarizationError,
      length: meetingMinutes.length,
      preview: meetingMinutes.slice(0, 100),
    });

    return NextResponse.json({
      transcript: transcriptText,
      meetingMinutes: meetingMinutes,
      summarization: {
        success: summarizationSuccess,
        error: summarizationError,
        model: model, // Use the actual model that was used
      },
      model: {
        transcription: "scribe_v1",
        summarization: model, // Use the actual model that was used
      },
      language: "fa",
    });
  } catch (error) {
    console.error("[voice-meeting-minutes] Error:", error);

    const errorMessage =
      error instanceof Error ? error.message : "Unknown error";
    return NextResponse.json(
      { error: `Processing failed: ${errorMessage}` },
      { status: 500 }
    );
  }
}
