import { NextRequest, NextResponse } from "next/server";
import { ElevenLabsClient } from "@elevenlabs/elevenlabs-js";
import Groq from "groq-sdk";
import { MEETING_PROCESSOR_CONFIG } from "@/lib/config";
import {
  checkTokenLimits,
  truncateForTokenLimit,
} from "@/lib/token-management";
import {
  chunkTranscript,
  mergeChunkSummaries,
  getChunkingRecommendations,
  TranscriptChunk,
} from "@/lib/transcript-chunker";

// Types for ElevenLabs response (align with voice-transcribe route)
interface TranscriptWord {
  text: string;
  start?: number;
  end?: number;
  type?: string;
  speakerId?: string;
  logprob?: number;
}

// Function to format transcript with speaker labels (copied from voice-transcribe)
function formatTranscriptWithSpeakers(words: TranscriptWord[]): string {
  if (!words || words.length === 0) {
    return "No transcript available";
  }

  let formattedTranscript = "";
  let currentSpeaker = "";
  let currentSentence = "";

  for (const word of words) {
    if (word.speakerId && word.speakerId !== currentSpeaker) {
      if (currentSentence.trim()) {
        formattedTranscript += currentSentence.trim() + "\n\n";
      }
      currentSpeaker = word.speakerId;
      const speakerNumber = currentSpeaker.replace("speaker_", "");
      const speakerLabel = `Speaker ${parseInt(speakerNumber) + 1}`;
      formattedTranscript += `${speakerLabel}\n`;
      currentSentence = "";
    }
    if (word.text) {
      currentSentence += word.text + " ";
    }
  }

  if (currentSentence.trim()) {
    formattedTranscript += currentSentence.trim();
  }

  return formattedTranscript;
}

/**
 * Create a fallback summary when LLM summarization fails
 */
function createFallbackSummary(
  transcript: string,
  language: "fa" | "en" = "fa"
): string {
  if (language === "fa") {
    return `### üìå ÿÆŸÑÿßÿµŸá ÿÆŸàÿØ⁄©ÿßÿ± ÿ¨ŸÑÿ≥Ÿá

**ÿ™Ÿàÿ¨Ÿá**: ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ŸáŸàÿ¥ŸÖŸÜÿØ ÿ®ÿß ŸÖÿ¥⁄©ŸÑ ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ. ÿß€åŸÜ ÿÆŸÑÿßÿµŸá ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿßÿ≥ÿ™.

#### üìä ÿßÿ∑ŸÑÿßÿπÿßÿ™ ⁄©ŸÑ€å
- **ÿ∑ŸàŸÑ ŸÖÿ™ŸÜ**: ${transcript.length} ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±
- **ÿ™ÿÆŸÖ€åŸÜ ÿ≤ŸÖÿßŸÜ**: ${Math.round(transcript.length / 200)} ÿØŸÇ€åŸÇŸá ÿµÿ≠ÿ®ÿ™

#### üìù ŸÜ⁄©ÿßÿ™ ⁄©ŸÑ€åÿØ€å
- ŸÖÿ™ŸÜ ÿ¨ŸÑÿ≥Ÿá ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿ¥ÿØŸá ÿßÿ≥ÿ™
- ÿ®ÿ±ÿß€å ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ÿØŸÇ€åŸÇ‚Äåÿ™ÿ±ÿå ŸÑÿ∑ŸÅÿßŸã ÿØŸàÿ®ÿßÿ±Ÿá ÿ™ŸÑÿßÿ¥ ⁄©ŸÜ€åÿØ
- €åÿß ŸÅÿß€åŸÑ ÿµŸàÿ™€å ⁄©Ÿàÿ™ÿßŸá‚Äåÿ™ÿ±€å ÿ¢ŸæŸÑŸàÿØ ⁄©ŸÜ€åÿØ

---
*ÿß€åŸÜ ÿÆŸÑÿßÿµŸá ÿ®Ÿá ÿØŸÑ€åŸÑ ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØÿå ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿßÿ≥ÿ™.*`;
  } else {
    return `### üìå Auto-Generated Meeting Summary

**Note**: Smart summarization encountered an issue. This summary was auto-generated.

#### üìä General Information
- **Text Length**: ${transcript.length} characters
- **Estimated Duration**: ${Math.round(
      transcript.length / 200
    )} minutes of speech

#### üìù Key Points
- Meeting transcript was successfully processed
- For accurate summarization, please try again
- Or upload a shorter audio file

---
*This summary was auto-generated due to an error in smart processing.*`;
  }
}

export async function POST(request: NextRequest) {
  try {
    // Check for required API keys
    if (!process.env.ELEVENLABS_API_KEY) {
      return NextResponse.json(
        { error: "ELEVENLABS_API_KEY missing" },
        { status: 500 }
      );
    }

    if (!process.env.GROQ_API_KEY) {
      return NextResponse.json(
        { error: "GROQ_API_KEY missing" },
        { status: 500 }
      );
    }

    console.log("[voice-meeting-minutes] Received POST request");

    const formData = await request.formData();
    const audioFile = formData.get("audio") as Blob | null;
    // Optional enhancements: topics and template
    const topicsRaw = formData.get("topics");
    const templateRaw = formData.get("template");
    let topics: string[] | undefined;
    let template: string | undefined;
    if (typeof topicsRaw === "string") {
      try {
        const parsed = JSON.parse(topicsRaw);
        if (Array.isArray(parsed)) {
          topics = parsed.filter((t) => typeof t === "string");
        } else if (typeof parsed === "string") {
          topics = parsed
            .split(",")
            .map((s) => s.trim())
            .filter(Boolean);
        }
      } catch {
        topics = topicsRaw
          .split(",")
          .map((s) => s.trim())
          .filter(Boolean);
      }
    }
    if (typeof templateRaw === "string") {
      template = templateRaw.trim() || undefined;
    }

    if (!audioFile) {
      console.log("[voice-meeting-minutes] No audio file in formData");
      return NextResponse.json(
        { error: "`audio` field required" },
        { status: 400 }
      );
    }

    console.log("[voice-meeting-minutes] Audio file received:", {
      size: audioFile.size,
      type: audioFile.type,
    });

    // Step 1: Transcribe with ElevenLabs Scribe v1
    console.log(
      "[voice-meeting-minutes] Starting transcription with ElevenLabs..."
    );

    const elevenlabs = new ElevenLabsClient({
      apiKey: process.env.ELEVENLABS_API_KEY,
    });

    const transcription = await elevenlabs.speechToText.convert({
      file: audioFile,
      modelId: "scribe_v1",
      tagAudioEvents: true,
      languageCode: "fa", // Persian
      diarize: true,
    });

    console.log("[voice-meeting-minutes] ElevenLabs transcription completed");

    // Handle different response types from ElevenLabs
    let transcriptText: string;
    // When diarization words are available, mirror voice-transcribe speaker formatting
    const respObj = transcription as unknown as
      | {
          words?: TranscriptWord[];
          text?: string;
          transcription?: string;
          segments?: Array<{ text?: string }>;
        }
      | string
      | null;
    if (typeof respObj === "string") {
      transcriptText = respObj;
    } else if (respObj && typeof respObj === "object") {
      if (Array.isArray(respObj.words) && respObj.words.length > 0) {
        transcriptText = formatTranscriptWithSpeakers(respObj.words);
      } else if (typeof respObj.text === "string") {
        transcriptText = respObj.text;
      } else if (typeof respObj.transcription === "string") {
        transcriptText = respObj.transcription;
      } else if (Array.isArray(respObj.segments)) {
        transcriptText = respObj.segments
          .map((segment) => segment.text || "")
          .join(" ");
      } else {
        transcriptText = JSON.stringify(respObj);
      }
    } else {
      transcriptText = "No transcription result";
    }

    console.log("[voice-meeting-minutes] Transcript extracted:", {
      length: transcriptText.length,
      preview: transcriptText.slice(0, 100),
    });

    // Continue with summarization after transcription

    // Step 2: Summarize with Groq
    console.log("[voice-meeting-minutes] Starting summarization with Groq...");

    const groq = new Groq({
      apiKey: process.env.GROQ_API_KEY,
    });

    // Use model from config
    let model: string = MEETING_PROCESSOR_CONFIG.summarization.model;

    // Build dynamic prompt components based on optional topics and template
    const topicsInstruction =
      topics && topics.length > 0
        ? `\n- ÿ±Ÿà€å ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿ≤€åÿ± ÿ™ŸÖÿ±⁄©ÿ≤ ⁄©ŸÜ Ÿà ŸÖÿ∑ŸÖÿ¶ŸÜ ÿ¥Ÿà ŸæŸàÿ¥ÿ¥ ÿØÿßÿØŸá ÿ¥ŸàŸÜÿØ: ${topics
            .map((t) => `¬´${t}¬ª`)
            .join("ÿå ")}`
        : "";
    const templateInstruction = template
      ? `\n\nÿØÿ± ÿµŸàÿ±ÿ™ ÿßŸÖ⁄©ÿßŸÜÿå ÿÆÿ±Ÿàÿ¨€å ÿ±ÿß ŸÖÿ∑ÿßÿ®ŸÇ ŸÇÿßŸÑÿ® ÿ≤€åÿ± ÿ≥ÿßÿÆÿ™ÿßÿ±ÿ®ŸÜÿØ€å ⁄©ŸÜ (ÿØÿ± ÿµŸàÿ±ÿ™ ÿπÿØŸÖ ÿßŸÜÿ∑ÿ®ÿßŸÇ ⁄©ÿßŸÖŸÑÿå ŸÜÿ≤ÿØ€å⁄©‚Äåÿ™ÿ±€åŸÜ ÿ≥ÿßÿÆÿ™ÿßÿ± ŸÖŸÜÿ∑ŸÇ€å ÿ±ÿß ÿßÿ±ÿßÿ¶Ÿá ÿ®ÿØŸá):\n${template}`
      : "";

    const systemPrompt = `ÿ¥ŸÖÿß €å⁄© ÿØÿ≥ÿ™€åÿßÿ± Ÿáÿ≥ÿ™€åÿØ ⁄©Ÿá ÿ®ÿß€åÿØ ÿßÿ≤ ŸÖÿ™ŸÜ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿ¥ÿØŸá €å⁄© ÿ¨ŸÑÿ≥Ÿá ⁄©ÿßÿ±€å (ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å) ÿµŸàÿ±ÿ™ÿ¨ŸÑÿ≥Ÿá ÿ±ÿ≥ŸÖ€å Ÿà ÿ®€å‚Äåÿ∑ÿ±ŸÅ ÿ™Ÿá€åŸá ⁄©ŸÜ€åÿØ.

ŸÖÿ™ŸÜ Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ¥ÿßŸÖŸÑ ÿ¥ŸàÿÆ€åÿå ÿ≥⁄©Ÿàÿ™ÿå ÿµÿ≠ÿ®ÿ™‚ÄåŸáÿß€å ÿ®€å‚Äåÿ±ÿ®ÿ∑ €åÿß ÿ™⁄©ÿ±ÿßÿ±€å ÿ®ÿßÿ¥ÿØ. 
ŸÑÿ∑ŸÅÿßŸã ŸÅŸÇÿ∑ ÿ®ÿÆÿ¥‚ÄåŸáÿß€å ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß ŸÖÿ®ÿßÿ≠ÿ´ ⁄©ÿßÿ±€å Ÿà ÿßÿ≥⁄©ÿ±ÿßŸÖ ÿ±ÿß ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ⁄©ŸÜ€åÿØ.

Ÿàÿ∏ÿß€åŸÅ ÿ¥ŸÖÿß:
1. ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ŸÖÿ®ÿßÿ≠ÿ´ ŸÖŸáŸÖ ÿ¨ŸÑÿ≥Ÿá ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å ÿ±ÿ≥ŸÖ€å.
2. ÿ≠ÿ∞ŸÅ ⁄©ÿßŸÖŸÑ Ÿáÿ±⁄ØŸàŸÜŸá ŸÜÿ∏ÿ± ÿ¥ÿÆÿµ€åÿå ÿ¥ŸàÿÆ€åÿå €åÿß ŸÖÿ≠ÿ™Ÿàÿß€å ŸÜÿßŸÖÿ±ÿ™ÿ®ÿ∑.
3. ÿØÿ≥ÿ™Ÿá‚Äåÿ®ŸÜÿØ€å ÿÆÿ±Ÿàÿ¨€å ÿØÿ± ŸÇÿßŸÑÿ® ÿ≤€åÿ±:

### üìå ÿµŸàÿ±ÿ™ÿ¨ŸÑÿ≥Ÿá
- **ÿ™ÿßÿ±€åÿÆ ÿ¨ŸÑÿ≥Ÿá:** [ÿß⁄Øÿ± ÿ∞⁄©ÿ± ÿ¥ÿØ ÿ®ŸÜŸà€åÿ≥€åÿØÿå ÿØÿ± ÿ∫€åÿ± ÿß€åŸÜÿµŸàÿ±ÿ™ ÿÆÿßŸÑ€å ÿ®⁄Øÿ∞ÿßÿ±€åÿØ]  
- **ŸÜŸàÿπ ÿ¨ŸÑÿ≥Ÿá:** ÿ®ÿ±ŸÜÿßŸÖŸá‚Äåÿ±€åÿ≤€å / ⁄Øÿ±ŸàŸÖ€åŸÜ⁄Ø / ÿßÿ≥ÿ™ŸÜÿØÿ¢Ÿæ / ÿ≥ÿß€åÿ± (ÿØÿ± ÿµŸàÿ±ÿ™ ÿ™ÿ¥ÿÆ€åÿµ)  

#### ‚úÖ ÿ™ÿµŸÖ€åŸÖÿßÿ™ ⁄Øÿ±ŸÅÿ™Ÿá‚Äåÿ¥ÿØŸá
[ÿ™ŸÖÿßŸÖ ÿ™ÿµŸÖ€åŸÖ‚ÄåŸáÿß€å ŸÇÿ∑ÿπ€å ⁄©Ÿá ÿ™€åŸÖ ÿ®Ÿá ÿ¢ŸÜ ÿ±ÿ≥€åÿØ]

#### üìù Ÿàÿ∏ÿß€åŸÅ Ÿà ÿßŸÇÿØÿßŸÖ‚ÄåŸáÿß
[⁄©ÿßÿ±Ÿáÿß€å ŸÖÿ¥ÿÆÿµÿå ÿ¥ÿßŸÖŸÑ:  
- ÿ¥ÿ±ÿ≠ ⁄©ÿßÿ±  
- ŸÖÿ≥ÿ¶ŸàŸÑ (ÿØÿ± ÿµŸàÿ±ÿ™ ÿ∞⁄©ÿ± ŸÜÿßŸÖ)  
- ÿ≤ŸÖÿßŸÜ‚Äåÿ®ŸÜÿØ€å €åÿß ÿ∂ÿ±ÿ®‚ÄåÿßŸÑÿπÿ¨ŸÑ (ÿß⁄Øÿ± ⁄ØŸÅÿ™Ÿá ÿ¥ÿØ)  
]

#### ‚ùì ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿ®ÿßÿ≤ / ŸÜ€åÿßÿ≤ŸÖŸÜÿØ Ÿæ€å⁄Ø€åÿ±€å
[ŸÖŸàÿ∂Ÿàÿπÿßÿ™€å ⁄©Ÿá ŸÜÿ™€åÿ¨Ÿá‚Äå⁄Ø€åÿ±€å ŸÜÿ¥ÿØ Ÿà ÿ®ÿß€åÿØ ÿØÿ± ÿ¨ŸÑÿ≥ÿßÿ™ ÿ®ÿπÿØ€å ÿ®ÿ±ÿ±ÿ≥€å ÿ¥ŸàÿØ]

---

ÿ±ÿßŸáŸÜŸÖÿß:
- ÿßÿ≤ ÿ™⁄©ÿ±ÿßÿ± ŸÖÿ®ÿßÿ≠ÿ´ ŸÖÿ¥ÿßÿ®Ÿá ÿÆŸàÿØÿØÿßÿ±€å ⁄©ŸÜ€åÿØÿå ŸÅŸÇÿ∑ ŸÜÿ™€åÿ¨Ÿá ŸÜŸáÿß€å€å ÿ±ÿß ÿ∞⁄©ÿ± ⁄©ŸÜ€åÿØ.
- ÿß⁄Øÿ± ŸÖÿ≥ÿ¶ŸàŸÑ €åÿß ÿ≤ŸÖÿßŸÜ‚Äåÿ®ŸÜÿØ€å ÿ∞⁄©ÿ± ŸÜÿ¥ÿØÿå ÿÆÿßŸÑ€å ÿ®⁄Øÿ∞ÿßÿ±€åÿØ.
- ÿÆÿ±Ÿàÿ¨€å ÿ®ÿß€åÿØ ⁄©Ÿàÿ™ÿßŸáÿå ÿ¥ŸÅÿßŸÅ Ÿà ÿ≥ÿßÿÆÿ™ÿßÿ±€åÿßŸÅÿ™Ÿá ÿ®ÿßÿ¥ÿØ.
- Ÿá€å⁄Ü ŸÜÿ∏ÿ± €åÿß ÿ™ÿ≠ŸÑ€åŸÑ ÿ¥ÿÆÿµ€å ÿßÿ∂ÿßŸÅŸá ŸÜ⁄©ŸÜ€åÿØ.${topicsInstruction}${templateInstruction}`;

    const userPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ.${
      topics && topics.length > 0
        ? `\nÿ±Ÿà€å ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ŸÖŸÜÿ™ÿÆÿ® ⁄©ÿßÿ±ÿ®ÿ± ÿ™ŸÖÿ±⁄©ÿ≤ ⁄©ŸÜ: ${topics
            .map((t) => `¬´${t}¬ª`)
            .join("ÿå ")}`
        : ""
    }${template ? "\nŸÇÿßŸÑÿ® ÿ™ÿ±ÿ¨€åÿ≠€å ⁄©ÿßÿ±ÿ®ÿ± ŸÑÿ≠ÿßÿ∏ ÿ¥ŸàÿØ (ÿØÿ± ÿ≠ÿØ ÿßŸÖ⁄©ÿßŸÜ)." : ""}

${transcriptText}`;

    // Check if we need to chunk the transcript
    const chunkingRecommendations = getChunkingRecommendations(
      transcriptText.length,
      "fa"
    );
    console.log(`[voice-meeting-minutes] Chunking recommendations:`, {
      transcriptLength: transcriptText.length,
      estimatedTokens: chunkingRecommendations.estimatedTokens,
      estimatedChunks: chunkingRecommendations.estimatedChunks,
      maxTokensPerChunk:
        chunkingRecommendations.recommendedStrategy.maxTokensPerChunk,
      willChunk: chunkingRecommendations.estimatedChunks > 1,
    });

    let meetingMinutes: string;
    let summarizationSuccess = false;
    let summarizationError: string | null = null;
    let chunks: TranscriptChunk[] = [];

    try {
      if (chunkingRecommendations.estimatedChunks > 1) {
        // Need to chunk the transcript
        console.log(
          `[voice-meeting-minutes] Chunking transcript into ${chunkingRecommendations.estimatedChunks} parts`
        );

        try {
          chunks = chunkTranscript(
            transcriptText,
            chunkingRecommendations.recommendedStrategy,
            "fa"
          );
          console.log(
            `[voice-meeting-minutes] Created ${chunks.length} chunks:`,
            chunks.map((chunk) => ({
              id: chunk.id,
              tokens: chunk.estimatedTokens,
              length: chunk.content.length,
            }))
          );

          if (chunks.length === 0) {
            console.log(
              "[voice-meeting-minutes] WARNING: No chunks created, falling back to single chunk processing"
            );
            throw new Error("Chunking failed - no chunks created");
          }
        } catch (chunkingError) {
          console.error(
            "[voice-meeting-minutes] Chunking failed, falling back to single chunk processing:",
            chunkingError
          );
          throw chunkingError; // This will be caught by the outer try-catch
        }

        // Process each chunk with OSS models only
        const chunkSummaries: string[] = [];

        for (let i = 0; i < chunks.length; i++) {
          const chunk = chunks[i];
          console.log(
            `[voice-meeting-minutes] Processing chunk ${i + 1}/${
              chunks.length
            } (${chunk.estimatedTokens} tokens)`
          );

          // Use config model for all chunks
          const chunkModel = MEETING_PROCESSOR_CONFIG.summarization.model;

          const chunkUserPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ.${
            topics && topics.length > 0
              ? `\nÿ±Ÿà€å ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ŸÖŸÜÿ™ÿÆÿ® ⁄©ÿßÿ±ÿ®ÿ± ÿ™ŸÖÿ±⁄©ÿ≤ ⁄©ŸÜ: ${topics
                  .map((t) => `¬´${t}¬ª`)
                  .join("ÿå ")}`
              : ""
          }${template ? "\nŸÇÿßŸÑÿ® ÿ™ÿ±ÿ¨€åÿ≠€å ⁄©ÿßÿ±ÿ®ÿ± ŸÑÿ≠ÿßÿ∏ ÿ¥ŸàÿØ (ÿØÿ± ÿ≠ÿØ ÿßŸÖ⁄©ÿßŸÜ)." : ""}

${chunk.content}`;

          try {
            const chunkCompletion = await groq.chat.completions.create({
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: chunkUserPrompt,
                },
              ],
              model: chunkModel,
              temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
              max_completion_tokens:
                MEETING_PROCESSOR_CONFIG.summarization.maxCompletionTokens,
              top_p: MEETING_PROCESSOR_CONFIG.summarization.topP,

              reasoning_effort: MEETING_PROCESSOR_CONFIG.summarization
                .reasoningEffort as "default" | "none" | null | undefined,
            });

            const chunkSummary =
              chunkCompletion.choices[0]?.message?.content ||
              "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
            chunkSummaries.push(chunkSummary);

            console.log(
              `[voice-meeting-minutes] Chunk ${
                i + 1
              } processed successfully with model ${chunkModel}`
            );

            // Add small delay between chunks to avoid rate limiting
            if (i < chunks.length - 1) {
              await new Promise((resolve) => setTimeout(resolve, 1000));
            }
          } catch (error) {
            console.error(
              `[voice-meeting-minutes] Error processing chunk ${i + 1}:`,
              error
            );

            // Try with OSS fallback model
            try {
              console.log(
                `[voice-meeting-minutes] Retrying chunk ${
                  i + 1
                } with fallback model`
              );
              const fallbackModel = "llama-3.1-8b-instant"; // OSS fallback

              const fallbackCompletion = await groq.chat.completions.create({
                messages: [
                  {
                    role: "system",
                    content: systemPrompt,
                  },
                  {
                    role: "user",
                    content: chunkUserPrompt,
                  },
                ],
                model: fallbackModel,
                temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
                max_completion_tokens:
                  MEETING_PROCESSOR_CONFIG.summarization.maxCompletionTokens,
                top_p: MEETING_PROCESSOR_CONFIG.summarization.topP,
                reasoning_effort: MEETING_PROCESSOR_CONFIG.summarization
                  .reasoningEffort as "default" | "none" | null | undefined,
              });

              const fallbackSummary =
                fallbackCompletion.choices[0]?.message?.content ||
                "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
              chunkSummaries.push(fallbackSummary);
              console.log(
                `[voice-meeting-minutes] Chunk ${
                  i + 1
                } processed with fallback model ${fallbackModel}`
              );
            } catch (fallbackError) {
              console.error(
                `[voice-meeting-minutes] Fallback also failed for chunk ${
                  i + 1
                }:`,
                fallbackError
              );
              chunkSummaries.push(
                `ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿÆÿ¥ ${i + 1}: ${
                  error instanceof Error ? error.message : "Unknown error"
                }`
              );
            }
          }
        }

        // Merge all chunk summaries
        console.log("[voice-meeting-minutes] Merging chunk summaries...");
        meetingMinutes = mergeChunkSummaries(chunkSummaries, "fa");
        console.log(
          `[voice-meeting-minutes] Final merged summary length: ${meetingMinutes.length} characters`
        );
      } else {
        // No chunking needed, process normally
        console.log(
          "[voice-meeting-minutes] No chunking needed, processing normally"
        );

        // Check token limits and get recommended action
        const tokenCheck = checkTokenLimits(
          systemPrompt,
          userPrompt,
          model,
          "fa"
        );
        console.log(`[voice-meeting-minutes] Token check:`, {
          estimatedTokens: tokenCheck.estimatedTokens,
          recommendedAction: tokenCheck.recommendedAction,
          isWithinLimit: tokenCheck.isWithinLimit,
        });

        // Handle token limit issues
        if (tokenCheck.recommendedAction === "error") {
          // Use config model (should handle large contexts)
          console.log(
            "[voice-meeting-minutes] Token limit exceeded, using config model"
          );
          model = MEETING_PROCESSOR_CONFIG.summarization.model;
        }

        if (tokenCheck.recommendedAction === "truncate") {
          console.log(
            "[voice-meeting-minutes] Truncating transcript to fit token limits"
          );
          const maxTokensForTranscript = 6000; // Leave room for system prompt
          transcriptText = truncateForTokenLimit(
            transcriptText,
            maxTokensForTranscript,
            "fa"
          );
          console.log(
            `[voice-meeting-minutes] Transcript truncated to ${transcriptText.length} characters`
          );

          // Recreate user prompt with truncated transcript
          const truncatedUserPrompt = `ŸÑÿ∑ŸÅÿßŸã ÿ±ŸàŸÜŸà€åÿ≥€å ÿ≤€åÿ± ÿ±ÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿÆŸÑÿßÿµŸá ÿ¨ŸÑÿ≥Ÿá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ:

${transcriptText}`;

          // Recheck token limits with OSS model
          const newTokenCheck = checkTokenLimits(
            systemPrompt,
            truncatedUserPrompt,
            model,
            "fa"
          );
          if (!newTokenCheck.isWithinLimit) {
            // Use config model (should handle large contexts)
            console.log(
              `[voice-meeting-minutes] Using config model for large context`
            );
            model = MEETING_PROCESSOR_CONFIG.summarization.model;
          }
        }

        // Process the transcript
        try {
          const completion = await groq.chat.completions.create({
            messages: [
              {
                role: "system",
                content: systemPrompt,
              },
              {
                role: "user",
                content: userPrompt,
              },
            ],
            model: model,
            temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
            max_completion_tokens:
              MEETING_PROCESSOR_CONFIG.summarization.maxCompletionTokens,
            top_p: MEETING_PROCESSOR_CONFIG.summarization.topP,
            reasoning_effort: MEETING_PROCESSOR_CONFIG.summarization
              .reasoningEffort as "default" | "none" | null | undefined,
          });

          meetingMinutes =
            completion.choices[0]?.message?.content || "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
          summarizationSuccess = true;
        } catch (apiError) {
          console.error(
            "[voice-meeting-minutes] API call failed, trying with fallback model:",
            apiError
          );

          // Try with OSS model as last resort
          try {
            const lastResortModel = "llama-3.1-8b-instant"; // OSS model
            console.log(
              `[voice-meeting-minutes] Trying with last resort model: ${lastResortModel}`
            );

            const fallbackCompletion = await groq.chat.completions.create({
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: userPrompt,
                },
              ],
              model: lastResortModel,
              temperature: MEETING_PROCESSOR_CONFIG.summarization.temperature,
              max_completion_tokens:
                MEETING_PROCESSOR_CONFIG.summarization.maxCompletionTokens,
              top_p: MEETING_PROCESSOR_CONFIG.summarization.topP,
              reasoning_effort: MEETING_PROCESSOR_CONFIG.summarization
                .reasoningEffort as "default" | "none" | null | undefined,
            });

            meetingMinutes =
              fallbackCompletion.choices[0]?.message?.content ||
              "ÿÆŸÑÿßÿµŸá‚Äåÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜÿ¥ÿØ";
            summarizationSuccess = true;
            model = lastResortModel; // Update the model used
            console.log(
              "[voice-meeting-minutes] Successfully processed with fallback model"
            );
          } catch (finalError) {
            console.error(
              "[voice-meeting-minutes] All models failed:",
              finalError
            );
            throw finalError; // This will be caught by the outer try-catch
          }
        }
      }
    } catch (error) {
      console.error("[voice-meeting-minutes] Summarization failed:", error);
      summarizationError =
        error instanceof Error ? error.message : "Unknown error";

      // Create a fallback summary based on the transcript
      meetingMinutes = createFallbackSummary(transcriptText, "fa");
      console.log(
        "[voice-meeting-minutes] Using fallback summary due to summarization failure"
      );
    }

    console.log("[voice-meeting-minutes] Summarization completed:", {
      success: summarizationSuccess,
      error: summarizationError,
      length: meetingMinutes.length,
      preview: meetingMinutes.slice(0, 100),
    });

    return NextResponse.json({
      transcript: transcriptText,
      meetingMinutes: meetingMinutes,
      processing: {
        transcriptReady: true,
        meetingMinutesReady: true,
      },
      preferences: {
        topics: topics || [],
        template: template || null,
      },
      summarization: {
        success: summarizationSuccess,
        error: summarizationError,
        model: model, // Use the actual model that was used
      },
      model: {
        transcription: "scribe_v1",
        summarization: model, // Use the actual model that was used
      },
      language: "fa",
    });
  } catch (error) {
    console.error("[voice-meeting-minutes] Error:", error);

    const errorMessage =
      error instanceof Error ? error.message : "Unknown error";
    return NextResponse.json(
      { error: `Processing failed: ${errorMessage}` },
      { status: 500 }
    );
  }
}
